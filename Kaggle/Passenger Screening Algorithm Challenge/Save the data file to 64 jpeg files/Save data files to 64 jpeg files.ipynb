{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "home = 'Z:\\\\MachineLearning\\\\Kaggle\\\\170812 Passenger\\\\Data\\\\'\n",
    "a3daps_dir = 'stage1_a3daps\\\\'\n",
    "jpeg_dir = 'stage1_jpeg_image\\\\'\n",
    "\n",
    "ID = '0a27d19c6ec397661b09f7d5998e0b14'\n",
    "\n",
    "a3daps_file = home + a3daps_dir + ID + '.a3daps'\n",
    "\n",
    "data = read_data(a3daps_file)\n",
    "\n",
    "for j in range(0, 64) :\n",
    "    fig = plt.figure(figsize = (16,16))\n",
    "    fig.add_subplot(1,1,1)\n",
    "    plt.imshow(np.flipud(data[:,:,j].transpose()), cmap = 'viridis')\n",
    "\n",
    "    image_file = home + jpeg_dir + ID + '_' + str(j) + '.jpg'\n",
    "    plt.savefig(image_file)\n",
    "    plt.close()\n",
    "\n",
    "# read_header() by William Cukierski\n",
    "# https://www.kaggle.com/wcukierski/reading-images\n",
    "def read_header(infile):\n",
    "    \"\"\"Read image header (first 512 bytes)\n",
    "    \"\"\"\n",
    "    h = dict()\n",
    "    fid = open(infile, 'r+b')\n",
    "    h['filename'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 20))\n",
    "    h['parent_filename'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 20))\n",
    "    h['comments1'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 80))\n",
    "    h['comments2'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 80))\n",
    "    h['energy_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['config_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['file_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['trans_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['scan_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['data_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['date_modified'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 16))\n",
    "    h['frequency'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['mat_velocity'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['num_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['num_polarization_channels'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['spare00'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['adc_min_voltage'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['adc_max_voltage'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['band_width'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['spare01'] = np.fromfile(fid, dtype = np.int16, count = 5)\n",
    "    h['polarization_type'] = np.fromfile(fid, dtype = np.int16, count = 4)\n",
    "    h['record_header_size'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['word_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['word_precision'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['min_data_value'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['max_data_value'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['avg_data_value'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['data_scale_factor'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['data_units'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['surf_removal'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['edge_weighting'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['x_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['y_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['z_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['t_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['spare02'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['x_return_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_return_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_return_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['scan_orientation'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['scan_direction'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['data_storage_order'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['scanner_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['x_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['t_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['num_x_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['num_y_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['num_z_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['num_t_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['x_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_acc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_acc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_acc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_motor_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_motor_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_motor_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_encoder_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_encoder_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_encoder_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['date_processed'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 8))\n",
    "    h['time_processed'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 8))\n",
    "    h['depth_recon'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_max_travel'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_max_travel'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['elevation_offset_angle'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['roll_offset_angle'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_max_travel'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['azimuth_offset_angle'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['adc_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['spare06'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['scanner_radius'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_offset'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_offset'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_offset'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['t_delay'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['range_gate_start'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['range_gate_end'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['ahis_software_version'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['spare_end'] = np.fromfile(fid, dtype = np.float32, count = 10)\n",
    "    return h\n",
    "\n",
    "# read_data() by William Cukierski\n",
    "# https://www.kaggle.com/wcukierski/reading-images\n",
    "def read_data(infile):\n",
    "    \"\"\"Read any of the 4 types of image files, returns a numpy array of the image contents\n",
    "    \"\"\"\n",
    "    extension = os.path.splitext(infile)[1]\n",
    "    h = read_header(infile)\n",
    "    nx = int(h['num_x_pts'])\n",
    "    ny = int(h['num_y_pts'])\n",
    "    nt = int(h['num_t_pts'])\n",
    "    fid = open(infile, 'rb')\n",
    "    fid.seek(512) #skip header\n",
    "    if extension == '.aps' or extension == '.a3daps':\n",
    "        if(h['word_type']==7): #float32\n",
    "            data = np.fromfile(fid, dtype = np.float32, count = nx * ny * nt)\n",
    "        elif(h['word_type']==4): #uint16\n",
    "            data = np.fromfile(fid, dtype = np.uint16, count = nx * ny * nt)\n",
    "        data = data * h['data_scale_factor'] #scaling factor\n",
    "        data = data.reshape(nx, ny, nt, order='F').copy() #make N-d image\n",
    "    elif extension == '.a3d':\n",
    "        if(h['word_type']==7): #float32\n",
    "            data = np.fromfile(fid, dtype = np.float32, count = nx * ny * nt)\n",
    "        elif(h['word_type']==4): #uint16\n",
    "            data = np.fromfile(fid, dtype = np.uint16, count = nx * ny * nt)\n",
    "        data = data * h['data_scale_factor'] #scaling factor\n",
    "        data = data.reshape(nx, nt, ny, order='F').copy() #make N-d image\n",
    "    elif extension == '.ahi':\n",
    "        data = np.fromfile(fid, dtype = np.float32, count = 2* nx * ny * nt)\n",
    "        data = data.reshape(2, ny, nx, nt, order='F').copy()\n",
    "        real = data[0,:,:,:].copy()\n",
    "        imag = data[1,:,:,:].copy()\n",
    "    fid.close()\n",
    "    if extension != '.ahi':\n",
    "        return data\n",
    "    else:\n",
    "        return real, imag"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
